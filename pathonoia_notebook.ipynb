{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import parmap\n",
    "import datetime\n",
    "import os\n",
    "from pathonoia import pathonoia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this folder will be created and for every dataset and sample corresponding subfolders\n",
    "OUTPUT_DIR = \"./OUTPUT/\"\n",
    "\n",
    "# The Inputfolder should contain one or more fasta files\n",
    "# These files should be samples of the same dataset\n",
    "# if the dataset was originally host RNAseq, align it first to the host's transcriptome and extract the unmapped reads\n",
    "# the fasta files should contain all (host-)unmapped reads \n",
    "# the unmapped reads can be extracted from the alignment BAM file with SAMtools:\n",
    "\n",
    "# samtools view -hb -f 4 host_align.bam > host_unmapped.bam\n",
    "# samtools view host_unmapped.bam | awk \\'{OFS=\"\\\\t\"; print \">\"$1\"\\\\n\"$10}\\' - > host_unmapped.fa\n",
    "\n",
    "inputfolder = \"./dataset/\"\n",
    "\n",
    "# make sure Kraken 2 is installed on your system along with its index build with k=31 AND l=31 \n",
    "# Instructions for creating this index can be found at the end of this notebook\n",
    "krakenTOOL=\"../tools/kraken2/kraken2\"\n",
    "krakenDB=\"../tools/kraken2/db/kraken2_k31\"\n",
    "pathonoia.checkKrakenInstall(krakenTOOL,krakenDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell, these are definitions / functions, only\n",
    "\n",
    "def processDataset(inputfolder):\n",
    "    print(inputfolder)\n",
    "    ds = inputfolder.rsplit(\"/\", 2)[1]\n",
    "    print(ds)\n",
    "    argumentList = []\n",
    "    for file in os.listdir(inputfolder):\n",
    "        if os.path.isfile(inputfolder+file):\n",
    "            if file.endswith(\".fa\") or file.endswith(\".fasta\"):           \n",
    "                sample = file.replace(\".fasta\",\"\").replace(\".fa\",\"\")\n",
    "                odir = OUTPUT_DIR + ds + \"/\" + sample\n",
    "                s1 = inputfolder + file\n",
    "                tup = (ds, odir, sample, s1)\n",
    "                argumentList.append(tup)\n",
    "            else:\n",
    "                print(file + \" is not a fasta file, PASS\")\n",
    "        else:\n",
    "            print(file + \" is not a file! PASS\")\n",
    "            \n",
    "    print(str(len(argumentList)) + \" samples to process\")\n",
    "    \n",
    "    if not pathonoia.checkKrakenInstall(krakenTOOL, krakenDB):\n",
    "        print(\"Problem with Kraken Installation. ABORT\")\n",
    "        return()\n",
    "\n",
    "    allNucPerTaxList = parmap.starmap(runOneSample, argumentList, pm_processes=1, pm_pbar=True)\n",
    "    \n",
    "    print(\"merge and save results\")\n",
    "    allNucPerTax = dict()\n",
    "    for i in range(len(argumentList)):\n",
    "        allNucPerTax[argumentList[i][3]] = allNucPerTaxList[i]\n",
    "\n",
    "    dsdf = pathonoia.mergeNucTaxDataframes(allNucPerTax)\n",
    "    dsdf.to_csv(OUTPUT_DIR + ds + \"/\" + ds + \"_contamination.csv\")\n",
    "    print(ds + \" done\")\n",
    "    return(dsdf)\n",
    "\n",
    "def runOneSample(ds, outputdir, samplename, sample1):   \n",
    "    print(outputdir)\n",
    "    if(os.path.isdir(outputdir)):\n",
    "        print(outputdir + \" ALREADY EXISTS\")\n",
    "    else:\n",
    "        os.makedirs(outputdir)\n",
    "    outdir_prefix = outputdir + \"/\" + samplename\n",
    "    logfile = open(outdir_prefix + \"_pathonoiaLOG_\"+datetime.datetime.now().strftime(\"%Y%m%d\")+\".log\", \"a\") \n",
    "    \n",
    "    print(\"++++++++++++++\", file = logfile)\n",
    "    print(samplename + \"\\n\", file = logfile)\n",
    "    \n",
    "    print(\"Kraken2\", file = logfile)\n",
    "    if (os.path.isfile(outdir_prefix + \"_krakenalign.txt\")):\n",
    "        print(\"Kraken results already available, skip\", file = logfile)\n",
    "    else:\n",
    "        execute(KRAKENcommand(outdir_prefix, sample1),logfile)\n",
    "\n",
    "    print(\"evaluate\", file = logfile)\n",
    "    nucCutOff = 100\n",
    "    print(\"nucCutOff = \" + str(nucCutOff), file = logfile)\n",
    "    nucPerTax = pathonoia.evalKrakenAlign(outdir_prefix, sample1, nucCutOff, logfile)\n",
    "    print(\"DONE\", file = logfile)\n",
    "    logfile.close()\n",
    "    print(samplename + \" done\")\n",
    "    return(nucPerTax)\n",
    "\n",
    "def execute(cmd, logfile):\n",
    "    print(cmd, file = logfile)\n",
    "    answer = \"cmd didnt run, uncommented\"\n",
    "    answer = os.system(cmd)\n",
    "    print(answer, file = logfile)    \n",
    "\n",
    "def KRAKENcommand(outdir_prefix, sample):\n",
    "    #if you want to change settings here, make sure the spaces in the string stay the way they are\n",
    "    krakenPARAMETERS = \"--db \" + krakenDB + \" --use-names --threads 8 \"\n",
    "    outputPARAMETER = \"--output \" + outdir_prefix + \"_krakenalign.txt --report \" + outdir_prefix + \"_krakenreport.txt \"\n",
    "    samplePARAMETER = sample\n",
    "    cmd = krakenTOOL + \" \" + krakenPARAMETERS + outputPARAMETER + samplePARAMETER\n",
    "    return(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processDataset(inputfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO BE COMMENTED \n",
    "# CHECK IN AT LATER STATE\n",
    "\n",
    "ds_contamination = processDataset(inputfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_contamination.loc[ds_contamination.phylo_level.str.contains(\"S\", na=False),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nucCutOff = 100\n",
    "df = pd.DataFrame.from_dict(taxMap, orient='index', columns=['nucleotides'])\n",
    "df.sort_values(by = \"nucleotides\", ascending=False, inplace=True)\n",
    "df_all = df.join(taxInfo)\n",
    "df = df_all.loc[df_all.phylo_level.str.contains(\"S\", na=False),]\n",
    "df = df.loc[df[\"nucleotides\"]>nucCutOff,]\n",
    "\n",
    "for taxId in df.index:\n",
    "    species_nucs = df.loc[taxId,\"nucleotides\"]\n",
    "    parent = df.loc[taxId,\"parent\"]\n",
    "    level = taxInfo.loc[parent,\"phylo_level\"]\n",
    "    while(\"S\" in level or \"G\" in level or \"F\" in level):\n",
    "        if(parent in df_all.index):\n",
    "            species_nucs = species_nucs + df_all.loc[parent,\"nucleotides\"]\n",
    "        parent = taxInfo.loc[parent,\"parent\"]\n",
    "        level = taxInfo.loc[parent,\"phylo_level\"]\n",
    "    df.loc[taxId,\"nucleotides\"] = species_nucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup Kraken 2 for Pathonoia\n",
    "follow these commands one by one to build a Kraken Index that works with Pathonoia\n",
    "\n",
    "    git clone https://github.com/DerrickWood/kraken2.git\n",
    "    cd kraken2/\n",
    "    ./install_kraken2.sh .\n",
    "    mkdir db\n",
    "    ./kraken2-build --download-taxonomy --db db/bacvir_k31 #?--skip-maps\n",
    "    ./kraken2-build --download-library bacteria --db db/bacvir_k31 --use-ftp\n",
    "    ./kraken2-build --download-library viral --db db/bacvir_k31 --use-ftp\n",
    "\n",
    "    ./kraken2-build --build --db db/bacvir_k31 --threads 8 --kmer-len 31 --minimizer-len 31\n",
    "\n",
    "    ./kraken2-build --clean --db db/bacvir_k31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
